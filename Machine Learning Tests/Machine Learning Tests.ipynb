{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-m7ZVyh-bXLm",
        "outputId": "a179a6eb-ba0a-45aa-bd6f-1101085d08f6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Upload 1 to 3 V2c files manually\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Function to parse .V2c files\n",
        "def parse_v2c_data(contents):\n",
        "    acceleration = []\n",
        "    for line in contents:\n",
        "        try:\n",
        "            values = [float(val) for val in line.strip().split()]\n",
        "            acceleration.extend(values)\n",
        "        except ValueError:\n",
        "            continue\n",
        "    return np.array(acceleration)\n",
        "\n",
        "# Load and process uploaded files\n",
        "acc_arrays = []\n",
        "for filename in uploaded:\n",
        "    with open(filename, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "        acc = parse_v2c_data(lines)\n",
        "        acc_arrays.append(acc)\n",
        "\n",
        "# Make sure all arrays are the same length\n",
        "min_length = min(len(arr) for arr in acc_arrays)\n",
        "acc_arrays = [arr[:min_length] for arr in acc_arrays]\n",
        "\n",
        "# Dynamically calculate magnitude\n",
        "acc_stack = np.vstack(acc_arrays)  # shape: (n_axes, n_points)\n",
        "magnitude = np.sqrt(np.sum(acc_stack**2, axis=0))  # shape: (n_points,)\n",
        "\n",
        "# Create a single row DataFrame with 'acc1', ..., 'accN', and 'earthquake?' = 1\n",
        "def create_row_df(magnitude, count):\n",
        "    segment = magnitude[:count]\n",
        "    data = {f'acc{i+1}': val for i, val in enumerate(segment)}\n",
        "    data['earthquake?'] = 1\n",
        "    return pd.DataFrame([data])\n",
        "\n",
        "# Append or create Excel files\n",
        "def append_to_excel(filename, new_row_df):\n",
        "    if os.path.exists(filename):\n",
        "        existing_df = pd.read_excel(filename)\n",
        "        combined_df = pd.concat([existing_df, new_row_df], ignore_index=True)\n",
        "    else:\n",
        "        combined_df = new_row_df\n",
        "    combined_df.to_excel(filename, index=False)\n",
        "    return combined_df\n",
        "\n",
        "# Process all sizes\n",
        "df_200 = create_row_df(magnitude, 200)\n",
        "df_500 = create_row_df(magnitude, 500)\n",
        "df_1000 = create_row_df(magnitude, 1000)\n",
        "\n",
        "# Save to Excel\n",
        "df_200_full = append_to_excel(\"earthquake_200.xlsx\", df_200)\n",
        "df_500_full = append_to_excel(\"earthquake_500.xlsx\", df_500)\n",
        "df_1000_full = append_to_excel(\"earthquake_1000.xlsx\", df_1000)\n",
        "\n",
        "# Show results\n",
        "print(\"✅ Updated earthquake_200.xlsx:\")\n",
        "display(df_200_full.tail())\n",
        "\n",
        "print(\"✅ Updated earthquake_500.xlsx:\")\n",
        "display(df_500_full.tail())\n",
        "\n",
        "print(\"✅ Updated earthquake_1000.xlsx:\")\n",
        "display(df_1000_full.tail())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26cahKnA5esS",
        "outputId": "4045ba9e-54aa-4c7c-a0db-b9b463cd4c93"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Sampling setup\n",
        "fs = 1000  # Hz\n",
        "duration = 1  # seconds (enough for 1000 samples)\n",
        "samples = fs * duration\n",
        "t = np.linspace(0, duration, samples)\n",
        "\n",
        "# Signal generators\n",
        "def generate_human_walk():\n",
        "    freq = np.random.uniform(1.5, 3.0)\n",
        "    amp = np.random.uniform(0.1, 0.4)\n",
        "    noise = np.random.normal(0, 0.05, samples)\n",
        "    return amp * np.sin(2 * np.pi * freq * t) + noise\n",
        "\n",
        "def generate_truck_driveby():\n",
        "    freq = np.random.uniform(2.5, 5.0)\n",
        "    amp = np.random.uniform(0.5, 1.5)\n",
        "    decay = np.exp(-np.linspace(0, 3, samples))\n",
        "    noise = np.random.normal(0, 0.1, samples)\n",
        "    return amp * np.sin(2 * np.pi * freq * t) * decay + noise\n",
        "\n",
        "def generate_random_noise():\n",
        "    spikes = np.random.normal(0, 1, samples)\n",
        "    smooth = np.convolve(spikes, np.ones(20)/20, mode='same')\n",
        "    return smooth * np.random.uniform(0.1, 0.3)\n",
        "\n",
        "# Combined generator\n",
        "def generate_non_eq_signal():\n",
        "    kind = np.random.choice(['human', 'truck', 'noise'])\n",
        "    if kind == 'human':\n",
        "        return generate_human_walk()\n",
        "    elif kind == 'truck':\n",
        "        return generate_truck_driveby()\n",
        "    else:\n",
        "        return generate_random_noise()\n",
        "\n",
        "# Append to Excel\n",
        "def append_to_excel(filename, signals, sample_size):\n",
        "    rows = []\n",
        "    for signal in signals:\n",
        "        trimmed = signal[:sample_size]\n",
        "        row = {f'acc{i+1}': val for i, val in enumerate(trimmed)}\n",
        "        row['earthquake?'] = 0\n",
        "        rows.append(row)\n",
        "\n",
        "    df_new = pd.DataFrame(rows)\n",
        "\n",
        "    if os.path.exists(filename):\n",
        "        df_existing = pd.read_excel(filename)\n",
        "        df_combined = pd.concat([df_existing, df_new], ignore_index=True)\n",
        "    else:\n",
        "        df_combined = df_new\n",
        "\n",
        "    df_combined.to_excel(filename, index=False)\n",
        "    print(f\"✅ Added {len(signals)} non-earthquake signals to {filename}\")\n",
        "\n",
        "# Generate and distribute to all Excel files\n",
        "non_eq_signals = [generate_non_eq_signal() for _ in range(3)]\n",
        "append_to_excel('earthquake_200.xlsx', non_eq_signals, 200)\n",
        "append_to_excel('earthquake_500.xlsx', non_eq_signals, 500)\n",
        "append_to_excel('earthquake_1000.xlsx', non_eq_signals, 1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "jqFfUIAwH_dg",
        "outputId": "43722202-3723-4131-8013-0d433ce0b59f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, confusion_matrix, precision_score, recall_score,\n",
        "    f1_score, roc_curve, auc, roc_auc_score\n",
        ")\n",
        "\n",
        "def evaluate_naive_bayes(file_path, label):\n",
        "    # Load the dataset\n",
        "    df = pd.read_excel(file_path)\n",
        "    X = df.drop(columns=['earthquake?'])\n",
        "    y = df['earthquake?']\n",
        "\n",
        "    # Split into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)\n",
        "\n",
        "    # Initialize and train the model\n",
        "    model = GaussianNB()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions and probabilities\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # ROC curve and AUC\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "    auc_score = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "    # Plot ROC\n",
        "    plt.plot(fpr, tpr, label=f'{label} (AUC = {auc_score:.2f})')\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "    return {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall (True Positive Rate)\": recall,\n",
        "        \"F1 Score\": f1,\n",
        "        \"True Positive Rate\": tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
        "        \"False Positive Rate\": fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
        "        \"True Negative Rate\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"False Negative Rate\": fn / (fn + tp) if (fn + tp) > 0 else 0,\n",
        "        \"ROC AUC\": auc_score\n",
        "    }\n",
        "\n",
        "# Evaluate each file\n",
        "results_200 = evaluate_naive_bayes(\"earthquake_200.xlsx\", \"200 Accels\")\n",
        "results_500 = evaluate_naive_bayes(\"earthquake_500.xlsx\", \"500 Accels\")\n",
        "results_1000 = evaluate_naive_bayes(\"earthquake_1000.xlsx\", \"1000 Accels\")\n",
        "\n",
        "# Display metrics\n",
        "print(\"Results for 200 accelerations:\")\n",
        "print(results_200)\n",
        "print(\"\\nResults for 500 accelerations:\")\n",
        "print(results_500)\n",
        "print(\"\\nResults for 1000 accelerations:\")\n",
        "print(results_1000)\n",
        "\n",
        "# Finalize and show ROC plot\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Naive Bayes ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "1_GnpdtePh28",
        "outputId": "bf2d966d-45eb-4494-94ac-465fe3af6e6d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, confusion_matrix, precision_score, recall_score,\n",
        "    f1_score, fbeta_score, roc_curve, auc\n",
        ")\n",
        "\n",
        "def evaluate_gradient_boosting(file_path, label):\n",
        "    df = pd.read_excel(file_path)\n",
        "    X = df.drop(columns=['earthquake?'])\n",
        "    y = df['earthquake?']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "    model = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]  # Probabilities for ROC\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    f2 = fbeta_score(y_test, y_pred, beta=2)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # Plot ROC curve\n",
        "    plt.plot(fpr, tpr, label=f'{label} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "    return {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1 Score\": f1,\n",
        "        \"F2 Score\": f2,\n",
        "        \"True Positive Rate\": tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
        "        \"False Positive Rate\": fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
        "        \"True Negative Rate\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"False Negative Rate\": fn / (fn + tp) if (fn + tp) > 0 else 0,\n",
        "        \"Confusion Matrix\": confusion_matrix(y_test, y_pred),\n",
        "        \"ROC AUC\": roc_auc\n",
        "    }\n",
        "\n",
        "# Run for each file and collect results\n",
        "results_200 = evaluate_gradient_boosting(\"earthquake_200.xlsx\", \"200 Accelerations\")\n",
        "results_500 = evaluate_gradient_boosting(\"earthquake_500.xlsx\", \"500 Accelerations\")\n",
        "results_1000 = evaluate_gradient_boosting(\"earthquake_1000.xlsx\", \"1000 Accelerations\")\n",
        "\n",
        "# Finalize ROC plot\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
        "plt.title(\"ROC Curve - Gradient Boosting\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print results\n",
        "print(\"Results for 200 accelerations:\")\n",
        "print(results_200)\n",
        "print(\"\\nResults for 500 accelerations:\")\n",
        "print(results_500)\n",
        "print(\"\\nResults for 1000 accelerations:\")\n",
        "print(results_1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW21wCIDkLp4",
        "outputId": "5f90881a-c468-41fb-e324-2968a523b261"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "for file in [\"earthquake_200.xlsx\", \"earthquake_500.xlsx\", \"earthquake_1000.xlsx\"]:\n",
        "    df = pd.read_excel(file)\n",
        "    counts = df['earthquake?'].value_counts()\n",
        "    print(f\"\\n{file}:\")\n",
        "    print(f\" - No earthquake (0): {counts.get(0, 0)}\")\n",
        "    print(f\" - Earthquake (1): {counts.get(1, 0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VY2NyQcmldjh",
        "outputId": "6cb769fd-ee83-47e9-a25f-654e71a7bcae"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    fbeta_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# Store curves for plotting later\n",
        "roc_data = []\n",
        "\n",
        "def evaluate_lightgbm(file_path, label):\n",
        "    df = pd.read_excel(file_path)\n",
        "    X = df.drop(columns=['earthquake?'])\n",
        "    y = df['earthquake?']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    model = LGBMClassifier(n_estimators=50, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    f2 = fbeta_score(y_test, y_pred, beta=2)\n",
        "    auc = roc_auc_score(y_test, y_proba)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "    # Save ROC data\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "    roc_data.append((fpr, tpr, auc, label))\n",
        "\n",
        "    return {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1 Score\": f1,\n",
        "        \"F2 Score\": f2,\n",
        "        \"ROC AUC\": auc,\n",
        "        \"True Positive Rate\": tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
        "        \"False Positive Rate\": fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
        "        \"True Negative Rate\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"False Negative Rate\": fn / (fn + tp) if (fn + tp) > 0 else 0,\n",
        "        \"Confusion Matrix\": confusion_matrix(y_test, y_pred),\n",
        "    }\n",
        "\n",
        "# Run evaluations\n",
        "results_200 = evaluate_lightgbm(\"earthquake_200.xlsx\", label=\"200 Accelerations\")\n",
        "results_500 = evaluate_lightgbm(\"earthquake_500.xlsx\", label=\"500 Accelerations\")\n",
        "results_1000 = evaluate_lightgbm(\"earthquake_1000.xlsx\", label=\"1000 Accelerations\")\n",
        "\n",
        "# Plot all ROC curves together\n",
        "plt.figure(figsize=(8, 6))\n",
        "for fpr, tpr, auc, label in roc_data:\n",
        "    plt.plot(fpr, tpr, label=f'{label} (AUC = {auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - LightGBM Models')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print results\n",
        "print(\"\\nResults for 200 accelerations:\")\n",
        "print(results_200)\n",
        "print(\"\\nResults for 500 accelerations:\")\n",
        "print(results_500)\n",
        "print(\"\\nResults for 1000 accelerations:\")\n",
        "print(results_1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "pg-Ga437Jdnh",
        "outputId": "e082c1bd-83a9-421b-dc54-85990a55aee3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, confusion_matrix, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, roc_curve\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def evaluate_random_forest(file_path, label):\n",
        "    # Load the dataset\n",
        "    df = pd.read_excel(file_path)\n",
        "    X = df.drop(columns=['earthquake?'])\n",
        "    y = df['earthquake?']\n",
        "\n",
        "    # Split into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)\n",
        "\n",
        "    # Initialize the Random Forest model and fit it to the data\n",
        "    model = RandomForestClassifier(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions and probabilities for ROC curve\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_proba)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "    # ROC curve data\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "    plt.plot(fpr, tpr, label=f\"{label} (AUC = {auc:.2f})\")\n",
        "\n",
        "    return {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall (True Positive Rate)\": recall,\n",
        "        \"F1 Score\": f1,\n",
        "        \"ROC AUC\": auc,\n",
        "        \"True Positive Rate\": tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
        "        \"False Positive Rate\": fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
        "        \"True Negative Rate\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"False Negative Rate\": fn / (fn + tp) if (fn + tp) > 0 else 0,\n",
        "    }\n",
        "\n",
        "# Evaluate and collect results\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "results_200 = evaluate_random_forest(\"earthquake_200.xlsx\", label=\"200 Accelerations\")\n",
        "results_500 = evaluate_random_forest(\"earthquake_500.xlsx\", label=\"500 Accelerations\")\n",
        "results_1000 = evaluate_random_forest(\"earthquake_1000.xlsx\", label=\"1000 Accelerations\")\n",
        "\n",
        "# Plot settings\n",
        "plt.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - Random Forest')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print results\n",
        "print(\"\\nResults for 200 accelerations:\")\n",
        "print(results_200)\n",
        "\n",
        "print(\"\\nResults for 500 accelerations:\")\n",
        "print(results_500)\n",
        "\n",
        "print(\"\\nResults for 1000 accelerations:\")\n",
        "print(results_1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK1Gp5TjOkpY",
        "outputId": "42d48160-4f2b-44d6-97db-330737a96d63"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Input and output file mappings\n",
        "files = {\n",
        "    \"earthquake_200.xlsx\": \"earthquake_200.xlsx\",\n",
        "    \"earthquake_500.xlsx\": \"earthquake_500.xlsx\",\n",
        "    \"earthquake_1000.xlsx\": \"earthquake_1000.xlsx\"\n",
        "}\n",
        "\n",
        "for input_file, output_file in files.items():\n",
        "    # Load the Excel file with headers\n",
        "    df = pd.read_excel(input_file)\n",
        "\n",
        "    # Separate features and label\n",
        "    feature_columns = df.columns[:-1]         # All columns except the last one\n",
        "    label_column = df.columns[-1]             # The 'earthquake?' column\n",
        "\n",
        "    # Take absolute value of only the acceleration features\n",
        "    df[feature_columns] = df[feature_columns].abs()\n",
        "\n",
        "    # Save the result to a new Excel file\n",
        "    df.to_excel(output_file, index=False)\n",
        "    print(f\"Saved: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8xFpyFqyf8pl"
      },
      "outputs": [],
      "source": [
        "#This is to ensure all the results are positive\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def save_random_forest_model(file_path, model_save_path):\n",
        "    # Load dataset\n",
        "    df = pd.read_excel(file_path)\n",
        "    X = df.drop(columns=['earthquake?'])\n",
        "    y = df['earthquake?']\n",
        "\n",
        "    # Train/test split\n",
        "    X_train, _, y_train, _ = train_test_split(X, y, test_size=0.35, random_state=42)\n",
        "\n",
        "    # Train model\n",
        "    model = RandomForestClassifier(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Save trained model\n",
        "    joblib.dump(model, model_save_path)\n",
        "\n",
        "# Save the model trained on 200 acceleration readings\n",
        "save_random_forest_model(\"earthquake_200.xlsx\", \"random_forest_200.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlWUlgFwggZD",
        "outputId": "48316c66-889f-412c-fe59-3ffba9970326"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# Load the trained Random Forest model\n",
        "model = joblib.load(\"random_forest_200.pkl\")\n",
        "\n",
        "# Load the 200-acceleration dataset (used to train this model)\n",
        "data = pd.read_excel(\"earthquake_200.xlsx\")\n",
        "\n",
        "# Filter to get only false alarms (earthquake? == 0)\n",
        "false_alarms = data[data[\"earthquake?\"] == 0]\n",
        "\n",
        "# Check if there are any false alarms\n",
        "if false_alarms.empty:\n",
        "    print(\"No false alarm samples found in the dataset.\")\n",
        "else:\n",
        "    # Select the first false alarm sample (drop the 'earthquake?' column)\n",
        "    sample = false_alarms.iloc[0, :-1].values\n",
        "\n",
        "    # Convert to DataFrame (model expects 2D input)\n",
        "    new_data = pd.DataFrame([sample])\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(new_data)[0]\n",
        "\n",
        "    print(f\"Prediction: {prediction} (0 = False Alarm, 1 = Earthquake)\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
